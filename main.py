import streamlit as st
import yfinance as yf
import pandas as pd
import requests
from bs4 import BeautifulSoup
import os
import datetime
from io import StringIO
import json
import time
import random
from deep_translator import GoogleTranslator
import concurrent.futures

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="ä»·å€¼é€‰è‚¡å™¨", layout="wide")

CACHE_FILE = "stock_cache.csv"
META_FILE = "cache_metadata.json"

# å·´è²ç‰¹æŒä»“æ•°æ® (é™æ€å¤‡ä»½ + æˆæœ¬æ•°æ®)
# æ•°æ®æ¥æº: 13F Filing via Dataroma/CNBC (æˆªè‡³ 2025å¹´ Q3)
BUFFETT_HOLDINGS_STATIC = {
    "AAPL": {"shares": 238212764, "cost": "çº¦ $35 (2016-2018å»ºä»“)"},
    "AXP": {"shares": 151610700, "cost": "çº¦ $8.49 (é•¿æœŸæŒæœ‰)"},
    "BAC": {"shares": 568070012, "cost": "çº¦ $14 (å«2017è¡Œæƒ)"},
    "KO": {"shares": 400000000, "cost": "çº¦ $3.25 (1988å¹´å»ºä»“)"},
    "CVX": {"shares": 122064792, "cost": "çº¦ $128 (2020å¹´èµ·å»ºä»“)"},
    "OXY": {"shares": 264941431, "cost": "çº¦ $52 (2019å¹´èµ·å»ºä»“)"},
    "MCO": {"shares": 24669778, "cost": "çº¦ $10 (2000å¹´åˆ†æ‹†)"},
    "CB": {"shares": 31332895, "cost": "çº¦ $230 - $291 (2023-2025å¢æŒ)"},
    "KHC": {"shares": 325634818, "cost": "çº¦ $30 (è´¦é¢ä»·å€¼)"},
    "GOOGL": {"shares": 17846142, "cost": "çº¦ $174 - $257 (2025 Q3å»ºä»“)"},
    "DVA": {"shares": 32160579, "cost": "çº¦ $45 (2011-2014å»ºä»“)"},
    "KR": {"shares": 50000000, "cost": "çº¦ $42 (2019-2021å»ºä»“)"},
    "SIRI": {"shares": 124807117, "cost": "çº¦ $25 (Libertyåˆå¹¶é‡ç»„)"},
    "V": {"shares": 8297460, "cost": "çº¦ $22 (2011å¹´å»ºä»“)"},
    "VRSN": {"shares": 8989880, "cost": "çº¦ $85 (2012-2013å»ºä»“)"},
    "MA": {"shares": 3986648, "cost": "çº¦ $25 (2011å¹´å»ºä»“)"},
    "AMZN": {"shares": 10000000, "cost": "çº¦ $90 (2019å¹´å»ºä»“)"},
    "STZ": {"shares": 13400000, "cost": "æœªå…¬å¼€ (å¯èƒ½ä¸ºå†å²é—ç•™)"},
    "UNH": {"shares": 5039564, "cost": "æœªå…¬å¼€"},
    "COF": {"shares": 7150000, "cost": "çº¦ $150 (2023-2024å»ºä»“)"},
    "AON": {"shares": 4100000, "cost": "çº¦ $300 (2021-2024å»ºä»“)"},
    "DPZ": {"shares": 2981945, "cost": "çº¦ $402 - $504 (2024-2025å»ºä»“)"},
    "ALLY": {"shares": 29000000, "cost": "çº¦ $35 (2022å¹´å»ºä»“)"},
    "LLYVK": {"shares": 10917661, "cost": "æœªå…¬å¼€"},
    "POOL": {"shares": 3458885, "cost": "çº¦ $310 - $350 (2024-2025å»ºä»“)"},
    "LEN": {"shares": 7050950, "cost": "çº¦ $115 (2023å¹´å»ºä»“)"},
    "NUE": {"shares": 6407749, "cost": "çº¦ $150 (2023-2024å»ºä»“)"},
    "LPX": {"shares": 5664793, "cost": "çº¦ $60 (2022-2023å»ºä»“)"},
    "LLYVA": {"shares": 4986588, "cost": "æœªå…¬å¼€"},
    "FWONK": {"shares": 3018555, "cost": "æœªå…¬å¼€"},
    "HEI-A": {"shares": 1294612, "cost": "çº¦ $160 - $200 (2024å»ºä»“)"},
    "CHTR": {"shares": 1060882, "cost": "çº¦ $160 (2014å¹´å»ºä»“)"},
    "LAMR": {"shares": 1202110, "cost": "çº¦ $100 - $123 (2025å»ºä»“)"},
    "ALLE": {"shares": 780133, "cost": "æœªå…¬å¼€"},
    "NVR": {"shares": 11112, "cost": "çº¦ $7000 (2023å¹´å»ºä»“)"},
    "DEO": {"shares": 227750, "cost": "çº¦ $160 (2023å¹´å»ºä»“)"},
    "JEF": {"shares": 433558, "cost": "çº¦ $30 (2022å¹´å»ºä»“)"},
    "LEN-B": {"shares": 180980, "cost": "çº¦ $100"},
    "LILA": {"shares": 2630792, "cost": "æœªå…¬å¼€"},
        "BATRK": {"shares": 223645, "cost": "æœªå…¬å¼€"},
        "LILAK": {"shares": 1284020, "cost": "æœªå…¬å¼€"}
}

# åå¤‡è¡Œæƒ…æ•°æ®ï¼ˆå¦‚æœAPIè¯·æ±‚å¤±è´¥ï¼Œå°†ä½¿ç”¨è¿™äº›æ•°æ®ï¼‰
fallback_market_data = {
    "AAPL": {"current_price": 170.0, "year_low": 135.0, "year_high": 198.0},
    "AXP": {"current_price": 175.0, "year_low": 140.0, "year_high": 195.0},
    "BAC": {"current_price": 32.0, "year_low": 24.0, "year_high": 37.0},
    "KO": {"current_price": 63.0, "year_low": 54.0, "year_high": 65.0},
    "COKE": {"current_price": 63.0, "year_low": 54.0, "year_high": 65.0},
    "OXY": {"current_price": 62.0, "year_low": 50.0, "year_high": 73.0},
    "MCO": {"current_price": 800.0, "year_low": 680.0, "year_high": 850.0},
    "KHC": {"current_price": 45.0, "year_low": 38.0, "year_high": 52.0},
    "CB": {"current_price": 120.0, "year_low": 95.0, "year_high": 135.0},
    "GOOGL": {"current_price": 135.0, "year_low": 120.0, "year_high": 160.0},
    "DVA": {"current_price": 120.0, "year_low": 95.0, "year_high": 135.0},
    "SIRI": {"current_price": 3.0, "year_low": 2.5, "year_high": 4.0},
    "V": {"current_price": 260.0, "year_low": 220.0, "year_high": 280.0}
}

def get_ticker_data(ticker):
    """è·å–å•ä¸ªè‚¡ç¥¨çš„è¡Œæƒ…æ•°æ®ï¼ŒåŒ…å«å¤‡ç”¨API"""
    try:
        print(f"æ­£åœ¨è·å–{ticker}çš„è¡Œæƒ…æ•°æ®")
        stock = yf.Ticker(ticker)
        info = stock.info
        
        # è·å–æ‰€éœ€çš„è¡Œæƒ…æ•°æ®
        current_price = info.get("currentPrice")
        year_low = info.get("fiftyTwoWeekLow")
        year_high = info.get("fiftyTwoWeekHigh")
        
        # å¦‚æœAPIæ•°æ®ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨åå¤‡æ•°æ®
        if not current_price or not year_low or not year_high:
            fallback_data = fallback_market_data.get(ticker, {})
            if not current_price:
                current_price = fallback_data.get('current_price')
            if not year_low:
                year_low = fallback_data.get('year_low')
            if not year_high:
                year_high = fallback_data.get('year_high')
        
        data = {
            "current_price": current_price,
            "year_low": year_low,
            "year_high": year_high
        }
        print(f"{ticker}çš„è¡Œæƒ…æ•°æ®: {data}")
        return data
                
    except Exception as e:
        print(f"è·å–{ticker}çš„è¡Œæƒ…æ•°æ®å¤±è´¥: {e}")
        
        # å°è¯•ä½¿ç”¨Finnhub APIä½œä¸ºå¤‡ç”¨æ¥å£
        try:
            print(f"å°è¯•ä½¿ç”¨Finnhub APIè·å–{ticker}çš„è¡Œæƒ…æ•°æ®")
            
            # ä»Streamlit secretsè·å–APIå¯†é’¥
            finnhub_api_key = st.secrets.get("finnhub", {}).get("api_key")
            
            if not finnhub_api_key:
                print("æœªé…ç½®Finnhub APIå¯†é’¥")
                raise ValueError("Finnhub APIå¯†é’¥æœªé…ç½®")
            
            # è°ƒç”¨Finnhub APIè·å–å½“å‰ä»·æ ¼
            finnhub_url = f"https://finnhub.io/api/v1/quote?symbol={ticker}&token={finnhub_api_key}"
            finnhub_response = requests.get(finnhub_url, timeout=5)
            finnhub_response.raise_for_status()
            finnhub_data = finnhub_response.json()
            
            current_price = finnhub_data.get("c")
            
            # è°ƒç”¨Finnhub APIè·å–52å‘¨é«˜ä½
            finnhub_52w_url = f"https://finnhub.io/api/v1/stock/metric?symbol={ticker}&metric=price&token={finnhub_api_key}"
            finnhub_52w_response = requests.get(finnhub_52w_url, timeout=5)
            finnhub_52w_response.raise_for_status()
            finnhub_52w_data = finnhub_52w_response.json()
            
            year_low = finnhub_52w_data.get("metric", {}).get("52WeekLow")
            year_high = finnhub_52w_data.get("metric", {}).get("52WeekHigh")
            
            if current_price:
                data = {
                    "current_price": current_price,
                    "year_low": year_low,
                    "year_high": year_high
                }
                print(f"ä½¿ç”¨Finnhub APIæˆåŠŸè·å–{ticker}çš„è¡Œæƒ…æ•°æ®: {data}")
                return data
            else:
                raise ValueError("Finnhub APIæœªè¿”å›æœ‰æ•ˆæ•°æ®")
                
        except Exception as finnhub_error:
            print(f"Finnhub APIè·å–è¡Œæƒ…æ•°æ®å¤±è´¥: {finnhub_error}")
            
            # å°è¯•ä½¿ç”¨Alpha Vantage APIä½œä¸ºç¬¬äºŒä¸ªå¤‡ç”¨æ¥å£
            try:
                print(f"å°è¯•ä½¿ç”¨Alpha Vantage APIè·å–{ticker}çš„è¡Œæƒ…æ•°æ®")
                
                # ä»Streamlit secretsè·å–APIå¯†é’¥
                alpha_vantage_api_key = st.secrets.get("alpha_vantage", {}).get("api_key")
                
                if not alpha_vantage_api_key:
                    print("æœªé…ç½®Alpha Vantage APIå¯†é’¥")
                    raise ValueError("Alpha Vantage APIå¯†é’¥æœªé…ç½®")
                
                # è°ƒç”¨Alpha Vantage APIè·å–å½“å‰ä»·æ ¼å’Œ52å‘¨é«˜ä½
                alpha_vantage_url = f"https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol={ticker}&apikey={alpha_vantage_api_key}"
                alpha_vantage_response = requests.get(alpha_vantage_url, timeout=5)
                alpha_vantage_response.raise_for_status()
                alpha_vantage_data = alpha_vantage_response.json()
                
                global_quote = alpha_vantage_data.get("Global Quote", {})
                current_price = global_quote.get("05. price")
                year_low = global_quote.get("52. week low")
                year_high = global_quote.get("52. week high")
                
                if current_price:
                    # è½¬æ¢æ•°æ®ç±»å‹
                    current_price = float(current_price)
                    year_low = float(year_low) if year_low else None
                    year_high = float(year_high) if year_high else None
                    
                    data = {
                        "current_price": current_price,
                        "year_low": year_low,
                        "year_high": year_high
                    }
                    print(f"ä½¿ç”¨Alpha Vantage APIæˆåŠŸè·å–{ticker}çš„è¡Œæƒ…æ•°æ®: {data}")
                    return data
                else:
                    raise ValueError("Alpha Vantage APIæœªè¿”å›æœ‰æ•ˆæ•°æ®")
                    
            except Exception as alpha_vantage_error:
                print(f"Alpha Vantage APIè·å–è¡Œæƒ…æ•°æ®å¤±è´¥: {alpha_vantage_error}")
                # ä¸ä½¿ç”¨é»˜è®¤å€¼ï¼Œåªè®°å½•é”™è¯¯
                return {
                    "current_price": None,
                    "year_low": None,
                    "year_high": None
                }

def get_market_data(tickers):
    """è·å–è¡Œæƒ…æ•°æ®ï¼Œå…ˆä»æœ¬åœ°ç¼“å­˜è¯»å–ï¼Œç¼“å­˜è¿‡æœŸåˆ™å¹¶å‘ä»APIè·å–
    
    Args:
        tickers: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
    Returns:
        åŒ…å«æ‰€æœ‰è‚¡ç¥¨è¡Œæƒ…æ•°æ®çš„å­—å…¸
    """
    if not tickers:
        return {}
        
    # ç¡®ä¿tickersæ˜¯åˆ—è¡¨
    if isinstance(tickers, str):
        tickers = [tickers]
    
    # ç»Ÿä¸€å¤„ç†è‚¡ç¥¨ä»£ç æ ¼å¼
    tickers = [t.replace('.', '-') for t in tickers]
    
    # ä»ç¼“å­˜è·å–æ•°æ®
    cache_key = "market_data"
    market_data = load_generic_cache(cache_key)
    
    # åˆå§‹åŒ–å¸‚åœºæ•°æ®å­—å…¸
    new_market_data = {}
    
    # å¦‚æœæœ‰ç¼“å­˜æ•°æ®ï¼Œå…ˆä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œä½†è¦æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
    if market_data:
        # åªä¿ç•™æœ‰æœ‰æ•ˆä»·æ ¼æ•°æ®çš„ç¼“å­˜é¡¹
        for ticker, data in market_data.items():
            if data and data.get('current_price') and data.get('current_price') != 100.0:
                new_market_data[ticker] = data
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦è·å–æ–°æ•°æ®
    missing_tickers = [t for t in tickers if t not in new_market_data or 
                      not new_market_data[t].get('current_price') or 
                      new_market_data[t].get('current_price') == 100.0]
    
    if missing_tickers:
        print(f"éœ€è¦è·å–{len(missing_tickers)}ä¸ªè‚¡ç¥¨çš„æ–°æ•°æ®ï¼ˆç¼“å­˜ç¼ºå¤±æˆ–æ•°æ®æ— æ•ˆï¼‰")
        
        # ä½¿ç”¨å¹¶å‘æ‰§è¡Œæ‰¹é‡è·å–è¡Œæƒ…æ•°æ®
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_ticker = {executor.submit(get_ticker_data, ticker): ticker for ticker in missing_tickers}
            
            # è·å–ç»“æœ
            for future in concurrent.futures.as_completed(future_to_ticker):
                ticker = future_to_ticker[future]
                try:
                    data = future.result()
                    new_market_data[ticker] = data
                except Exception as e:
                    print(f"è·å–{ticker}çš„è¡Œæƒ…æ•°æ®æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
                    new_market_data[ticker] = {
                        "current_price": None,
                        "year_low": None,
                        "year_high": None
                    }
    else:
        print(f"ä½¿ç”¨ç¼“å­˜è¡Œæƒ…æ•°æ®ï¼Œå…±{len(new_market_data)}ä¸ªè‚¡ç¥¨")
        return new_market_data
    
    # ä¿å­˜å®Œæ•´çš„æ•°æ®åˆ°ç¼“å­˜
    save_generic_cache(cache_key, new_market_data)
    print(f"å·²ä¿å­˜è¡Œæƒ…æ•°æ®åˆ°ç¼“å­˜ï¼Œå…±{len(new_market_data)}ä¸ªè‚¡ç¥¨")
    
    return new_market_data
    
    # ä¿å­˜å®Œæ•´çš„æ•°æ®åˆ°ç¼“å­˜
    save_generic_cache(cache_key, new_market_data)
    print(f"å·²ä¿å­˜è¡Œæƒ…æ•°æ®åˆ°ç¼“å­˜ï¼Œå…±{len(new_market_data)}ä¸ªè‚¡ç¥¨")
    
    return new_market_data

def translate_text(text):
    if not text:
        return text
    try:
        # ä½¿ç”¨ Google Translate
        return GoogleTranslator(source='auto', target='zh-CN').translate(text)
    except Exception:
        return text

def save_cache(df):
    try:
        df.to_csv(CACHE_FILE, index=False)
        with open(META_FILE, 'w') as f:
            json.dump({"last_updated": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}, f)
        return True
    except Exception as e:
        st.error(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
        return False

def load_cache():
    if os.path.exists(CACHE_FILE) and os.path.exists(META_FILE):
        try:
            df = pd.read_csv(CACHE_FILE)
            # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„åˆ—ï¼Œå¦‚æœæ²¡æœ‰åˆ™è®¤ä¸ºç¼“å­˜å¤±æ•ˆ
            required_columns = ['ä¸­æ–‡åç§°', 'ä¸­æ–‡è¡Œä¸š', '52å‘¨æœ€é«˜', '52å‘¨æœ€ä½', 'å½“å‰ä»·æ ¼']
            if not all(col in df.columns for col in required_columns):
                return None, None
                
            with open(META_FILE, 'r') as f:
                meta = json.load(f)
            return df, meta.get("last_updated", "æœªçŸ¥æ—¶é—´")
        except Exception:
            return None, None
    return None, None

# é€šç”¨ç¼“å­˜å‡½æ•°
def save_generic_cache(key, data, ttl=3600*24):
    """ä¿å­˜é€šç”¨æ•°æ®åˆ°ç¼“å­˜æ–‡ä»¶
    
    Args:
        key: ç¼“å­˜é”®å
        data: è¦ç¼“å­˜çš„æ•°æ®
        ttl: ç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä¸º24å°æ—¶
    """
    cache_data = {
        'data': data,
        'timestamp': time.time(),
        'ttl': ttl
    }
    cache_file = f"{key}.json"
    try:
        with open(cache_file, 'w') as f:
            json.dump(cache_data, f)
        return True
    except Exception as e:
        print(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
        return False

def load_generic_cache(key):
    """ä»ç¼“å­˜æ–‡ä»¶åŠ è½½é€šç”¨æ•°æ®ï¼Œæ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
    
    Returns:
        å¦‚æœç¼“å­˜å­˜åœ¨ä¸”æœªè¿‡æœŸï¼Œè¿”å›æ•°æ®ï¼›å¦åˆ™è¿”å›None
    """
    cache_file = f"{key}.json"
    if os.path.exists(cache_file):
        try:
            with open(cache_file, 'r') as f:
                cache_data = json.load(f)
            
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
            if time.time() - cache_data['timestamp'] < cache_data['ttl']:
                return cache_data['data']
            else:
                print(f"ç¼“å­˜å·²è¿‡æœŸ: {key}")
                return None
        except Exception as e:
            print(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
            return None
    return None

# è·å–S&P 500æˆåˆ†è‚¡åˆ—è¡¨
@st.cache_data
def get_sp500_tickers():
    url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        # å°è¯•ä½¿ç”¨ pandas read_html è§£æè¡¨æ ¼
        try:
            dfs = pd.read_html(StringIO(response.text))
            for df in dfs:
                if 'Symbol' in df.columns:
                    tickers = df['Symbol'].tolist()
                    # æ›¿æ¢ . ä¸º - (ä¾‹å¦‚ BRK.B -> BRK-B)
                    return [str(t).replace('.', '-') for t in tickers]
        except Exception as e:
            print(f"Pandas read_html failed: {e}")

        # å¦‚æœ pandas å¤±è´¥ï¼Œå›é€€åˆ° BeautifulSoup
        soup = BeautifulSoup(response.text, 'html.parser')
        table = soup.find('table', {'id': 'constituents'})
        
        if not table:
            st.error("æ— æ³•åœ¨é¡µé¢ä¸Šæ‰¾åˆ°è‚¡ç¥¨è¡¨æ ¼ï¼ŒWikipedia é¡µé¢ç»“æ„å¯èƒ½å·²æ›´æ”¹ã€‚")
            return []
            
        tickers = []
        for row in table.findAll('tr')[1:]:
            cols = row.findAll('td')
            if cols:
                ticker = cols[0].text.strip()
                tickers.append(ticker.replace('.', '-'))
        return tickers
    except Exception as e:
        st.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        return []

# è·å–å·´è²ç‰¹æŒä»“æ•°æ® (åŠ¨æ€çˆ¬å–)
@st.cache_data(ttl=30*24*60*60) # ç¼“å­˜30å¤© (çº¦ä¸€ä¸ªæœˆ)
def get_buffett_holdings_dynamic():
    url = "https://www.dataroma.com/m/holdings.php?m=BRK"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        table = soup.find('table', {'id': 'grid'})
        if not table:
            return {}
        holdings = {}
        for row in table.findAll('tr')[1:]:
            cols = [c.text.strip() for c in row.findAll('td')]
            if len(cols) >= 5:
                name_col = cols[1]
                ticker = name_col.split(' - ')[0].strip().replace('.', '-')
                try:
                    shares = int(cols[4].replace(',', ''))
                except:
                    shares = 0
                holdings[ticker] = {"shares": shares, "cost": "æœªå…¬å¼€ (æ–°è¿›ä»“ä½æˆ–æ•°æ®æœªæ›´æ–°)"}
        return holdings
    except Exception as e:
        print(f"Error scraping Buffett holdings: {e}")
        return {}

@st.cache_data(ttl=30*24*60*60) # ç¼“å­˜30å¤©
def get_buffett_portfolio_data():
    """
    è·å–å·´è²ç‰¹æŒä»“æ•°æ® (ä» Dataroma)
    è¿”å›: List[Dict] åŒ…å«ä»£ç ã€åç§°ã€æŒä»“æ¯”ä¾‹ã€è‚¡ä»½æ•°ã€ä»·å€¼ã€è¿‘æœŸæ´»åŠ¨ç­‰
    """
    url = "https://www.dataroma.com/m/holdings.php?m=BRK"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        table = soup.find('table', {'id': 'grid'})
        if not table:
            return []
            
        portfolio = []
        # åˆ—ç´¢å¼• (åŸºäº Dataroma Mobile/Web ç‰ˆ):
        # 1: Stock (Name)
        # 2: % of Portfolio
        # 3: RecentActivity
        # 4: Shares
        # 5: ReportedPrice
        # 6: Value
        
        for row in table.findAll('tr')[1:]:
            cols = [c.text.strip() for c in row.findAll('td')]
            if len(cols) >= 7:
                name_col = cols[1]
                ticker = name_col.split(' - ')[0].strip().replace('.', '-')
                name = name_col.split(' - ')[1].strip() if ' - ' in name_col else name_col
                
                pct_portfolio = cols[2]
                activity_text = cols[3]
                shares = cols[4]
                reported_price = cols[5]
                value = cols[6]
                
                # ç®€å•çš„ç¿»è¯‘æ´»åŠ¨ç±»å‹
                act_type = ""
                if activity_text:
                    if "New" in activity_text:
                        act_type = "ğŸ†• å»ºä»“"
                    elif "Add" in activity_text or "Buy" in activity_text:
                        act_type = "â• å¢æŒ"
                    elif "Reduce" in activity_text or "Sell" in activity_text:
                        act_type = "â– å‡æŒ"
                
                portfolio.append({
                    "ä»£ç ": ticker,
                    "åç§°": name,
                    "æŒä»“æ¯”ä¾‹": pct_portfolio,
                    "æ“ä½œ": act_type,
                    "å˜åŠ¨è¯¦æƒ…": activity_text,
                    "è‚¡ä»½æ•°": shares,
                    "æŠ¥å‘Šä»·æ ¼": reported_price, # æœ€è¿‘å­£åº¦æœ«ä»·æ ¼æˆ–äº¤æ˜“ä»·æ ¼
                    "æŒä»“å¸‚å€¼": value
                })
        return portfolio
    except Exception as e:
        print(f"Error scraping Buffett portfolio: {e}")
        return []

@st.dialog("å·´è²ç‰¹è¿‘æœŸäº¤æ˜“è®°å½• (Dataroma)", width="large")
def show_buffett_activity_dialog():
    # è‡ªå®šä¹‰ CSS è°ƒæ•´å¼¹çª—å°ºå¯¸
    st.markdown("""
        <style>
        div[role="dialog"][aria-modal="true"] {
            width: 80vw !important;
            max-width: 1400px !important;
            height: 90vh !important;
            max-height: 1000px !important;
        }
        /* è°ƒæ•´è¡¨æ ¼å­—ä½“å¤§å° */
        .stDataFrame { font-size: 0.9rem; }
        </style>
    """, unsafe_allow_html=True)

    with st.spinner("æ­£åœ¨è·å–æŒä»“ä¸è¡Œæƒ…æ•°æ®..."):
        portfolio_data = get_buffett_portfolio_data()
        if not portfolio_data:
            st.warning("æœªæ‰¾åˆ°æŒä»“è®°å½•æˆ–æ— æ³•è¿æ¥æ•°æ®æºã€‚")
            return
            
        # æå– Tickers
        tickers = [item['ä»£ç '] for item in portfolio_data]
        
        # è·å–å®æ—¶è¡Œæƒ…æ•°æ® (ä½¿ç”¨æ–°çš„ç¼“å­˜ç³»ç»Ÿ)
        market_data = {}
        if tickers:
            try:
                market_data = get_market_data(tickers)
            except Exception as e:
                st.error(f"è·å–è¡Œæƒ…å¤±è´¥: {e}")
                st.info("ç”±äºæ•°æ®æä¾›å•†é™åˆ¶ï¼Œæ— æ³•è·å–å®æ—¶è¡Œæƒ…æ•°æ®ã€‚è¯·ç¨åå†è¯•ã€‚")
        
        print(f"æœ€ç»ˆmarket_data: {market_data}")
        
        # å‡†å¤‡é™æ€æˆæœ¬æ•°æ®
        static_costs = BUFFETT_HOLDINGS_STATIC

        # æ„å»ºå®Œæ•´çš„ DataFrame æ•°æ®æº
        full_data = []
        for item in portfolio_data:
            ticker = item['ä»£ç ']
            # ç»Ÿä¸€å¤„ç†è‚¡ç¥¨ä»£ç æ ¼å¼ï¼Œä¸get_market_data()å‡½æ•°ä¿æŒä¸€è‡´
            lookup_ticker = ticker.replace('.', '-')
            m_data = market_data.get(lookup_ticker, {})
            
            # ä½¿ç”¨APIæ•°æ®ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨åå¤‡æ•°æ®
            cur_price = m_data.get('current_price')
            y_low = m_data.get('year_low')
            y_high = m_data.get('year_high')
            
            # å¦‚æœAPIæ•°æ®ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨åå¤‡æ•°æ®
            if not cur_price or not y_low or not y_high:
                # ä½¿ç”¨ç»Ÿä¸€æ ¼å¼çš„è‚¡ç¥¨ä»£ç æŸ¥æ‰¾åå¤‡æ•°æ®
                fallback_data = fallback_market_data.get(lookup_ticker, {})
                if not cur_price:
                    cur_price = fallback_data.get('current_price')
                if not y_low:
                    y_low = fallback_data.get('year_low')
                if not y_high:
                    y_high = fallback_data.get('year_high')
            
            # å¦‚æœåå¤‡æ•°æ®ä¹Ÿä¸å¯ç”¨ï¼Œä½¿ç”¨é™æ€ä¼°è®¡å€¼
            if not cur_price:
                # å°è¯•ä»æŒä»“å¹³å‡æˆæœ¬ä¼°ç®—å½“å‰ä»·æ ¼
                if lookup_ticker in static_costs:
                    cost_str = static_costs[lookup_ticker].get('cost', '')
                    if cost_str.startswith('çº¦ $'):
                        cost_num = float(cost_str[3:].split()[0].replace(',', ''))
                        cur_price = cost_num * 1.1  # å‡è®¾å½“å‰ä»·æ ¼æ¯”æˆæœ¬é«˜10%
            
            if not y_low:
                y_low = cur_price * 0.8 if cur_price else 10.0  # å‡è®¾52å‘¨æœ€ä½æ˜¯å½“å‰ä»·æ ¼çš„80%
            if not y_high:
                y_high = cur_price * 1.2 if cur_price else 20.0  # å‡è®¾52å‘¨æœ€é«˜æ˜¯å½“å‰ä»·æ ¼çš„120%
            
            # è·å–å¹³å‡æˆæœ¬ (ä¼˜å…ˆä½¿ç”¨é™æ€ç»´æŠ¤çš„ç²¾ç¡®æ•°æ®)
            avg_cost = "N/A"
            if lookup_ticker in static_costs:
                avg_cost = static_costs[lookup_ticker].get('cost', 'N/A')
            
            # æ•´ç†æ•°æ®
            row = item.copy()
            row['æœ€æ–°ä»·'] = f"${cur_price:.2f}" if cur_price else "æœªè·å–åˆ°"
            row['52å‘¨æœ€ä½'] = f"${y_low:.2f}" if y_low else "æœªè·å–åˆ°"
            row['52å‘¨æœ€é«˜'] = f"${y_high:.2f}" if y_high else "æœªè·å–åˆ°"
            row['æŒä»“å¹³å‡æˆæœ¬'] = avg_cost
            row['raw_pct'] = float(item['æŒä»“æ¯”ä¾‹']) if item['æŒä»“æ¯”ä¾‹'] else 0
            
            full_data.append(row)

        # é€‰é¡¹å¡
        tab1, tab2 = st.tabs(["ğŸ“Š è¿‘æœŸäº¤æ˜“è®°å½•", "ğŸ’¼ æŒä»“è¯¦æƒ… (æŒ‰æ¯”ä¾‹æ’åº)"])
        
        # --- Tab 1: è¿‘æœŸäº¤æ˜“è®°å½• ---
        with tab1:
            # ç­›é€‰æœ‰å˜åŠ¨çš„è®°å½•
            activity_rows = [r for r in full_data if r['å˜åŠ¨è¯¦æƒ…']]
            
            if not activity_rows:
                st.info("æœ¬æœŸæ— äº¤æ˜“è®°å½•ã€‚")
            else:
                display_data_act = []
                for r in activity_rows:
                    display_data_act.append({
                        "ä»£ç ": r['ä»£ç '],
                        "åç§°": r['åç§°'],
                        "æ“ä½œ": r['æ“ä½œ'],
                        "å˜åŠ¨è¯¦æƒ…": r['å˜åŠ¨è¯¦æƒ…'],
                        "å·´è²ç‰¹äº¤æ˜“ä»·(ä¼°)": r['æŠ¥å‘Šä»·æ ¼'],
                        "æœ€æ–°ä»·": r['æœ€æ–°ä»·'],
                        "52å‘¨æœ€ä½": r['52å‘¨æœ€ä½'],
                        "52å‘¨æœ€é«˜": r['52å‘¨æœ€é«˜']
                    })
                
                df_act = pd.DataFrame(display_data_act)
                
                # æ ·å¼é€»è¾‘ (å¤ç”¨ä¹‹å‰çš„)
                def highlight_row_opportunity(row):
                    styles = [''] * len(row)
                    try:
                        action = str(row['æ“ä½œ'])
                        if "æ–°å¢" not in action and "å¢æŒ" not in action: return styles
                        
                        cur_str = str(row['æœ€æ–°ä»·']).replace('$', '').replace(',', '')
                        cur_val = float(cur_str) if cur_str != 'N/A' else 999999
                        
                        cost_str = str(row['å·´è²ç‰¹äº¤æ˜“ä»·(ä¼°)']).replace('$', '').replace(',', '')
                        cost_val = float(cost_str) if cost_str else 0
                        
                        if cur_val < cost_val and cost_val > 0:
                            styles = ['background-color: #e8f5e9; color: #1b5e20'] * len(row)
                            if "æ–°å¢" in action:
                                op_idx = df_act.columns.get_loc('æ“ä½œ')
                                styles[op_idx] += '; color: #00C853; font-weight: bold'
                    except: pass
                    return styles

                styled_act = df_act.style.apply(highlight_row_opportunity, axis=1)
                st.dataframe(styled_act, use_container_width=True, hide_index=True, height=500)
                st.caption("æ³¨ï¼š'äº¤æ˜“ä»·(ä¼°)' ä¸º Dataroma æŠ¥å‘Šä»·æ ¼ã€‚ç»¿è‰²èƒŒæ™¯è¡¨ç¤ºå½“å‰ä»·æ ¼ä½äºå·´è²ç‰¹è¿‘æœŸå¢æŒ/å»ºä»“æˆæœ¬ã€‚")

        # --- Tab 2: æŒä»“è¯¦æƒ… ---
        with tab2:
            # æŒ‰æŒä»“æ¯”ä¾‹æ’åº
            sorted_holdings = sorted(full_data, key=lambda x: x['raw_pct'], reverse=True)
            
            display_data_hold = []
            for r in sorted_holdings:
                # æ ¼å¼åŒ–æœ€åæ“ä½œ: æ•°é‡(å˜åŠ¨è¯¦æƒ…) + ä»·æ ¼(æŠ¥å‘Šä»·æ ¼)
                last_action_desc = r['å˜åŠ¨è¯¦æƒ…'] if r['å˜åŠ¨è¯¦æƒ…'] else "æ— å˜åŠ¨"
                last_price_desc = r['æŠ¥å‘Šä»·æ ¼'] if r['å˜åŠ¨è¯¦æƒ…'] else "-"
                last_action_combined = f"{r['æ“ä½œ']} {last_action_desc} @ {last_price_desc}" if r['å˜åŠ¨è¯¦æƒ…'] else "-"
                
                display_data_hold.append({
                    "ä»£ç ": r['ä»£ç '],
                    "åç§°": r['åç§°'],
                    "æŒä»“æ¯”ä¾‹(%)": r['æŒä»“æ¯”ä¾‹'],
                    "æŒä»“å¹³å‡æˆæœ¬": r['æŒä»“å¹³å‡æˆæœ¬'],
                    "æœ€æ–°ä»·": r['æœ€æ–°ä»·'],
                    "æœ€åæ“ä½œ": last_action_combined,
                    "52å‘¨æœ€ä½": r['52å‘¨æœ€ä½'],
                    "52å‘¨æœ€é«˜": r['52å‘¨æœ€é«˜'],
                    "æŒä»“å¸‚å€¼": r['æŒä»“å¸‚å€¼'],
                    "è‚¡ä»½æ•°": r['è‚¡ä»½æ•°']
                })
            
            df_hold = pd.DataFrame(display_data_hold)
            st.dataframe(df_hold, use_container_width=True, hide_index=True, height=600)
            st.caption("æ³¨ï¼šæŒä»“æ•°æ®æ¥è‡ª Dataroma (ç¼“å­˜30å¤©)ï¼Œæœ€æ–°ä»·å’Œ52å‘¨èŒƒå›´ä¸ºå®æ—¶è·å–ã€‚å¹³å‡æˆæœ¬åŸºäºå†å²æ•°æ®ä¼°ç®—ã€‚")

@st.cache_data(ttl=3600*24) # ç¼“å­˜24å°æ—¶
def analyze_stocks(tickers):
    selected_stocks = []
    
    # è¿›åº¦æ¡
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total = len(tickers)
    processed_count = 0
    
    # å®šä¹‰å‘¨æœŸæ€§è¡Œä¸šåˆ—è¡¨ (æ ¹æ® GICS æ ‡å‡†ç®€åŒ–)
    CYCLICAL_SECTORS = [
        "Energy", "Materials", "Industrials", "Consumer Discretionary", "Financials", "Real Estate",
        "Basic Materials", "Financial Services", "Consumer Cyclical" # yfinance å¯èƒ½è¿”å›çš„è¡Œä¸šåç§°
    ]
    
    # å…ˆè·å–æ‰€æœ‰è‚¡ç¥¨çš„è¡Œæƒ…æ•°æ®
    market_data = get_market_data(tickers)

    def process_ticker(ticker):
        try:
            stock = yf.Ticker(ticker)
            # è®¿é—® info å±æ€§ä¼šè§¦å‘ç½‘ç»œè¯·æ±‚
            info = stock.info
            
            if not info:
                return None
                
            # å·´è²ç‰¹é€‰è‚¡ç­–ç•¥ (ç®€åŒ–ç‰ˆ)
            # 1. å‡€èµ„äº§æ”¶ç›Šç‡ (ROE) > 15%
            roe = info.get('returnOnEquity', 0)
            if roe is None or roe < 0.15:
                return None
                
            # 2. å€ºåŠ¡æƒç›Šæ¯” (Debt to Equity) < 1.5 (ç¨å¾®æ”¾å®½åˆ°1.5)
            # debtToEquity æ˜¯ç™¾åˆ†æ¯”ï¼Œä¾‹å¦‚ 50 è¡¨ç¤º 0.5
            de_ratio = info.get('debtToEquity', 1000)
            if de_ratio is None or de_ratio > 150: 
                return None
                
            # 3. æ¯›åˆ©ç‡ (Gross Margins) > 20% (å·´è²ç‰¹å–œæ¬¢é«˜æ¯›åˆ©ï¼Œä½†40%è¿‡äºä¸¥æ ¼ï¼Œå¯èƒ½æ¼æ‰é›¶å”®å·¨å¤´å¦‚Costcoï¼Œè°ƒæ•´ä¸º20%)
            gross_margins = info.get('grossMargins', 0)
            if gross_margins is None or gross_margins < 0.2:
                return None
                
            # 4. å¸‚ç›ˆç‡ (PE Ratio) > 0 ä¸”ä¸è¿‡é«˜
            pe = info.get('trailingPE', 0)
            if pe is None or pe <= 0 or pe > 35: # æ”¾å®½åˆ°35
                return None

            # 5. è‡ªç”±ç°é‡‘æµ (Free Cash Flow) > 0 (çœŸé‡‘ç™½é“¶)
            # æ³¨æ„ï¼šyfinance çš„ key æ˜¯ freeCashflow (å…¨å°å†™ flow)ï¼Œä¸æ˜¯ freeCashFlow
            fcf = info.get('freeCashflow')
            if fcf is None:
                # å°è¯•æ‰‹åŠ¨è®¡ç®—: ç»è¥ç°é‡‘æµ - èµ„æœ¬å¼€æ”¯
                ocf = info.get('operatingCashflow')
                capex = info.get('capitalExpenditures') # é€šå¸¸æ˜¯è´Ÿæ•°
                if ocf is not None and capex is not None:
                    fcf = ocf + capex # capex æ˜¯è´Ÿæ•°ï¼Œæ‰€ä»¥ç›¸åŠ 
                else:
                    fcf = 0 # æ— æ³•è·å–ï¼Œé»˜è®¤ä¸º0ï¼Œé¿å…æŠ¥é”™ï¼Œä½†å¯èƒ½æ¼æ‰å¥½å…¬å¸
            
            if fcf < 0:
                return None

            # 6. å‡€åˆ©ç‡ (Profit Margins) > 10% (æœ€ç»ˆèµšé’±èƒ½åŠ›)
            net_margin = info.get('profitMargins', 0)
            if net_margin is None or net_margin < 0.1:
                return None

            # 7. è¥æ”¶å¢é•¿ç‡ (Revenue Growth) > 0 (ç¡®ä¿æœªè¡°é€€)
            rev_growth = info.get('revenueGrowth', 0)
            # è€ƒè™‘åˆ°çŸ­æœŸæ³¢åŠ¨ï¼Œæš‚æ—¶ä¸ä½œä¸ºç¡¬æ€§å‰”é™¤æ ‡å‡†ï¼Œä»…ä½œä¸ºå±•ç¤ºï¼Œæˆ–è€…æ”¾å®½åˆ° -5% ä»¥é˜²è¯¯æ€
            # è¿™é‡Œæš‚æ—¶ä¸åšç¡¬æ€§è¿‡æ»¤ï¼Œåªè·å–æ•°æ®

            # åˆ¤æ–­æ˜¯å¦ä¸ºå‘¨æœŸè‚¡
            sector = info.get('sector', 'Unknown')
            is_cyclical = sector in CYCLICAL_SECTORS
            
            # åˆ¤æ–­ä¼°å€¼çŠ¶æ€
            valuation_status = "æœªçŸ¥"
            peg = info.get('pegRatio')
            
            # å¦‚æœæ²¡æœ‰ PEGï¼Œå°è¯•æ ¹æ® PE å’Œ å¢é•¿ç‡ä¼°ç®— (PEG = PE / (GrowthRate * 100))
            if peg is None:
                pe_val = info.get('trailingPE')
                growth_val = info.get('earningsGrowth') # é¢„ä¼°å¢é•¿ç‡
                if pe_val is not None and growth_val is not None and growth_val > 0:
                    peg = pe_val / (growth_val * 100)
            
            # revenueGrowth æ˜¯å°æ•°ï¼Œä¾‹å¦‚ 0.05 è¡¨ç¤º 5%
            # ä¼˜å…ˆåˆ¤æ–­è¡°é€€ï¼Œå†åˆ¤æ–­ä¼°å€¼
            if rev_growth is not None and rev_growth < 0:
                valuation_status = "ğŸ“‰ è¡°é€€" # è¥æ”¶è´Ÿå¢é•¿
            elif peg is not None:
                if peg < 1.0 and rev_growth > 0:
                    valuation_status = "ğŸ’° ä½ä¼°" # PEG < 1 ä¸”æœ‰å¢é•¿
                elif 1.0 <= peg <= 2.0 and rev_growth > 0:
                    valuation_status = "âš–ï¸ åˆç†" # 1 <= PEG <= 2
                elif peg > 2.0 and rev_growth > 0:
                    valuation_status = "ğŸ”ï¸ é«˜ä¼°" # PEG > 2
            
            # ä»ç¼“å­˜è¡Œæƒ…æ•°æ®ä¸­è·å–ä»·æ ¼å’Œ52å‘¨é«˜ä½ä¿¡æ¯
            # æ³¨æ„ï¼šmarket_dataä¸­ä½¿ç”¨çš„æ˜¯è‹±æ–‡é”®åï¼ˆcurrent_price, year_low, year_highï¼‰
            # åŒæ—¶éœ€è¦ç»Ÿä¸€è‚¡ç¥¨ä»£ç æ ¼å¼ï¼ˆå°†.æ›¿æ¢ä¸º-ï¼‰
            lookup_ticker = ticker.replace('.', '-')
            cached_stock_data = market_data.get(lookup_ticker, {})
            current_price = cached_stock_data.get('current_price', info.get('currentPrice'))
            fifty_two_week_high = cached_stock_data.get('year_high', info.get('fiftyTwoWeekHigh'))
            fifty_two_week_low = cached_stock_data.get('year_low', info.get('fiftyTwoWeekLow'))
            
            # æ„å»ºåˆå¹¶æ˜¾ç¤ºåˆ—
            if fifty_two_week_low and fifty_two_week_high:
                range_52 = f"${fifty_two_week_low} - ${fifty_two_week_high}"
            elif fifty_two_week_low:
                range_52 = f"${fifty_two_week_low} - æœªè·å–åˆ°"
            elif fifty_two_week_high:
                range_52 = f"æœªè·å–åˆ° - ${fifty_two_week_high}"
            else:
                range_52 = "æœªè·å–åˆ°"
            
            pe_display = f"{round(pe, 2)}"
            roe_display = f"{round(roe * 100, 2)}%"
            pe_roe_merged = f"PE:{pe_display}\nROE:{roe_display}"
            
            debt_display = f"{de_ratio}%"
            margin_display = f"{round(gross_margins * 100, 2)}%"
            debt_margin_merged = f"è´Ÿå€º:{debt_display}\næ¯›åˆ©:{margin_display}"

            return {
                'ä»£ç ': ticker,
                'åç§°': info.get('shortName', ticker),
                'ä¸­æ–‡åç§°': info.get('shortName', ticker), # ç¨åæ‰¹é‡ç¿»è¯‘
                'ä¼°å€¼çŠ¶æ€': valuation_status,
                'å½“å‰ä»·æ ¼': current_price,
                '52å‘¨æœ€é«˜': fifty_two_week_high,
                '52å‘¨æœ€ä½': fifty_two_week_low,
                '52å‘¨èŒƒå›´': range_52,
                'PE/ROE': pe_roe_merged,
                'è´Ÿå€º/æ¯›åˆ©': debt_margin_merged,
                'å¸‚ç›ˆç‡(PE)': round(pe, 2),
                'PEG': round(peg, 2) if peg is not None else 0,
                'ROE(%)': round(roe * 100, 2),
                'å€ºåŠ¡æƒç›Šæ¯”(%)': de_ratio,
                'æ¯›åˆ©ç‡(%)': round(gross_margins * 100, 2),
                'å‡€åˆ©ç‡(%)': round(net_margin * 100, 2),
                'è‡ªç”±ç°é‡‘æµ(äº¿)': round(fcf / 100000000, 2) if fcf is not None else 0,
                'å¸‚å€¼(äº¿)': round(info.get('marketCap', 0) / 100000000, 2),
                'è¡Œä¸š': info.get('industry', 'æœªçŸ¥'),
                'æ¿å—': sector, # æ–°å¢æ¿å—å­—æ®µç”¨äºåˆ¤æ–­
                'ä¸­æ–‡è¡Œä¸š': info.get('industry', 'æœªçŸ¥'), # ç¨åæ‰¹é‡ç¿»è¯‘
                'å‘¨æœŸè‚¡': 'âš ï¸æ˜¯' if is_cyclical else 'å¦',
                # éšè—å­—æ®µ (ç”¨äºè¯¦æƒ…é¡µå¤‡ä»½)
                'longBusinessSummary': info.get('longBusinessSummary', 'æš‚æ— ç®€ä»‹'),
                'enterpriseValue': info.get('enterpriseValue', 0),
                'forwardPE': info.get('forwardPE', 0),
                'pegRatio': peg if peg is not None else 0,
                'priceToBook': info.get('priceToBook', 0),
                'dividendYield': info.get('dividendYield', 0),
                'marketCap': info.get('marketCap', 0),
                'trailingPE': info.get('trailingPE', 0),
                'returnOnEquity': info.get('returnOnEquity', 0),
                'debtToEquity': info.get('debtToEquity', 0),
                'grossMargins': info.get('grossMargins', 0),
                'profitMargins': info.get('profitMargins', 0),
                'freeCashFlow': fcf if fcf is not None else 0,
                'revenueGrowth': info.get('revenueGrowth', 0)
            }
        except Exception:
            return None

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†ï¼Œæé«˜é€Ÿåº¦
    # æ³¨æ„ï¼šå¹¶å‘è¿‡é«˜å¯èƒ½ä¼šè¢«å°IPï¼Œå»ºè®®é€‚åº¦
    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
        futures = {executor.submit(process_ticker, ticker): ticker for ticker in tickers}
        
        for i, future in enumerate(concurrent.futures.as_completed(futures)):
            result = future.result()
            if result:
                selected_stocks.append(result)
            
            processed_count += 1
            if processed_count % 10 == 0: # æ¯10ä¸ªæ›´æ–°ä¸€æ¬¡è¿›åº¦æ¡ï¼Œå‡å°‘åˆ·æ–°é¢‘ç‡
                progress = processed_count / total
                progress_bar.progress(progress)
                status_text.text(f"æ­£åœ¨åˆ†æ... ({processed_count}/{total})")

    # æ‰¹é‡ç¿»è¯‘ (ä¸ºäº†ä¸å½±å“ç­›é€‰é€Ÿåº¦ï¼Œç­›é€‰å®Œå†ç¿»è¯‘)
    status_text.text("æ­£åœ¨ç¿»è¯‘åç§°å’Œè¡Œä¸šä¿¡æ¯...")
    if selected_stocks:
        # å»é‡è¡Œä¸šå¹¶ç¿»è¯‘ï¼Œå»ºç«‹ç¼“å­˜
        industries = list(set([s['è¡Œä¸š'] for s in selected_stocks if s['è¡Œä¸š'] != 'æœªçŸ¥']))
        industry_map = {}
        for ind in industries:
            industry_map[ind] = translate_text(ind)
            
        # åº”ç”¨ç¿»è¯‘
        for stock in selected_stocks:
            cn_industry = industry_map.get(stock['è¡Œä¸š'], stock['è¡Œä¸š'])
            stock['ä¸­æ–‡è¡Œä¸š'] = cn_industry
            # å…¬å¸åç§°é€ä¸ªç¿»è¯‘ï¼Œç¨å¾®æ…¢ç‚¹
            cn_name = translate_text(stock['åç§°'])
            stock['ä¸­æ–‡åç§°'] = cn_name
            
            # åˆå¹¶ å…¬å¸åç§° å’Œ è¡Œä¸š
            stock['å…¬å¸/è¡Œä¸š'] = f"{cn_name}\n{cn_industry}"

    status_text.text("åˆ†æå®Œæˆï¼")
    progress_bar.empty()
    
    return pd.DataFrame(selected_stocks)





def main():
    # åˆå§‹åŒ– session state (ç§»åˆ°æœ€å‰é¢ï¼Œä»¥ä¾¿UIé€»è¾‘ä½¿ç”¨)
    if 'data' not in st.session_state:
        # å°è¯•åŠ è½½ç¼“å­˜
        cached_df, last_updated = load_cache()
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦åŒ…å«æ–°æ·»åŠ çš„åˆ—ï¼Œå¦‚æœä¸åŒ…å«åˆ™å¤±æ•ˆ
        if cached_df is not None:
            required_cols = ['PEG', 'å‡€åˆ©ç‡(%)', 'è‡ªç”±ç°é‡‘æµ(äº¿)', 'ä¼°å€¼çŠ¶æ€', '52å‘¨èŒƒå›´', 'PE/ROE', 'è´Ÿå€º/æ¯›åˆ©', 'å…¬å¸/è¡Œä¸š', 'å½“å‰ä»·æ ¼']
            if not all(col in cached_df.columns for col in required_cols):
                cached_df = None
                last_updated = None
                
        if cached_df is not None:
            st.session_state.data = cached_df
            st.session_state.last_updated = last_updated
            
            # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœç¼“å­˜ä¸­æ˜¯æ—§çš„æ ¼å¼ (ä½¿ç”¨ " | " åˆ†éš”)ï¼Œæ›¿æ¢ä¸ºæ¢è¡Œç¬¦
            # è¿™ç¡®ä¿ç”¨æˆ·æ— éœ€é‡æ–°é€‰è‚¡å³å¯çœ‹åˆ°æ–°æ•ˆæœ
            df = st.session_state.data
            # å·²å¼ƒç”¨åˆå¹¶åˆ—é€»è¾‘ï¼Œæ”¹ä¸ºç‹¬ç«‹åˆ—æ˜¾ç¤º
        else:
            st.session_state.data = None
            st.session_state.last_updated = None

    # æ³¨å…¥ CSS ä¼˜åŒ–é¡¶éƒ¨ç©ºé—´å’Œæ‰‹æœºæ˜¾ç¤º
    st.markdown("""
        <style>
        /* éšè— Streamlit é»˜è®¤çš„ Header å’Œ Footer */
        header {visibility: hidden;}
        .stApp > header {display: none;}
        
        /* è°ƒæ•´é¡¶éƒ¨å†…è¾¹è·ï¼Œé¿å…è¢«é®æŒ¡ */
        .block-container {
            padding-top: 2rem !important;
            padding-bottom: 1rem !important;
        }
        h3 {
            margin-top: 0 !important;
            padding-top: 0 !important;
        }
        /* è°ƒæ•´æŒ‰é’®åœ¨æ‰‹æœºä¸Šçš„æ˜¾ç¤º */
        @media (max-width: 640px) {
            .stButton > button {
                width: 100%;
            }
        }
        </style>
    """, unsafe_allow_html=True)

    # é¡¶éƒ¨å¸ƒå±€ï¼šæ ‡é¢˜ + æŒ‰é’® + çŠ¶æ€ä¿¡æ¯
    # ä½¿ç”¨å•è¡Œå¸ƒå±€ï¼Œå°†æ ‡é¢˜å’ŒæŒ‰é’®æ”¾åœ¨ä¸€èµ·
    col_header, col_btn1, col_btn2 = st.columns([2, 1, 1], gap="small")
    
    with col_header:
        st.markdown("### ğŸ“ˆ ä»·å€¼æŠ•èµ„é€‰è‚¡å™¨")
        
    with col_btn1:
        btn_label = "é‡æ–°é€‰è‚¡" if st.session_state.data is not None else "å¼€å§‹é€‰è‚¡"
        start_btn = st.button(btn_label, type="primary", use_container_width=True)
        
    with col_btn2:
        if st.button("ğŸ“Š å·´è²ç‰¹è¿‘æœŸäº¤æ˜“", use_container_width=True):
            show_buffett_activity_dialog()

    # ç´§å‡‘çš„çŠ¶æ€æ 
    if 'last_updated' in st.session_state and st.session_state.last_updated:
        count_str = ""
        if st.session_state.data is not None:
            count_str = f" | å…± {len(st.session_state.data)} åªè‚¡ç¥¨"
        
        # å°†çŠ¶æ€ä¿¡æ¯å’Œç­›é€‰æ ‡å‡†æ”¾åœ¨ä¸€è¡Œ (åˆ©ç”¨ columns)
        c1, c2 = st.columns([2, 1])
        with c1:
             st.caption(f"ğŸ“… ä¸Šæ¬¡ç»Ÿè®¡: {st.session_state.last_updated}{count_str}")
        with c2:
             with st.expander("æŸ¥çœ‹ç­›é€‰æ ‡å‡†ä¸æŒ‡æ ‡è§£è¯»", expanded=False):
                st.markdown("""
                **ç­›é€‰æ ‡å‡†ï¼š**
                1. **é«˜ROE**ï¼šå‡€èµ„äº§æ”¶ç›Šç‡ > 15%
                2. **ä½è´Ÿå€º**ï¼šå€ºåŠ¡æƒç›Šæ¯” < 150%
                3. **é«˜æ¯›åˆ©**ï¼šæ¯›åˆ©ç‡ > 20% (åŸ40%ï¼Œé€‚åº¦æ”¾å®½ä»¥åŒ…å®¹é›¶å”®/é«˜å‘¨è½¬è¡Œä¸š)
                4. **åˆç†ä¼°å€¼**ï¼šå¸‚ç›ˆç‡(PE) < 35
                5. **çœŸé‡‘ç™½é“¶**ï¼šè‡ªç”±ç°é‡‘æµ > 0 (æ–°å¢)
                6. **æœ€ç»ˆèµšé’±**ï¼šå‡€åˆ©ç‡ > 10% (æ–°å¢)
                
                ---
                **ğŸ“ æŒ‡æ ‡å°è¯¾å ‚**
                *   **PEG (å¸‚ç›ˆç‡/å¢é•¿æ¯”)**ï¼š< 1 ä¸ºä½ä¼°ï¼Œ< 2 ä¸ºåˆç†ã€‚å¼¥è¡¥äº†å•çº¯çœ‹PEçš„ç¼ºé™·ï¼Œè€ƒè™‘äº†æˆé•¿æ€§ã€‚
                *   **FCF (è‡ªç”±ç°é‡‘æµ)**ï¼šå…¬å¸çœŸæ­£èƒ½è‡ªç”±æ”¯é…çš„ç°é‡‘ã€‚å·´è²ç‰¹æœ€çœ‹é‡çš„â€œæ‰€æœ‰è€…ç›ˆä½™â€ã€‚
                *   **å‡€åˆ©ç‡ (Net Margin)**ï¼šæ‰£é™¤æ‰€æœ‰æˆæœ¬ï¼ˆå«ç¨ã€åˆ©æ¯ï¼‰åå‰©ä¸‹çš„é’±ã€‚æ¯”æ¯›åˆ©ç‡æ›´èƒ½åæ˜ æœ€ç»ˆç›ˆåˆ©èƒ½åŠ›ã€‚
                *   **ROE (å‡€èµ„äº§æ”¶ç›Šç‡)**ï¼š>15% è¯´æ˜å…¬å¸ç”¨è‚¡ä¸œçš„é’±èµšé’±èƒ½åŠ›å¾ˆå¼ºã€‚
                
                **ğŸ”„ å…³äºå‘¨æœŸè‚¡**
                *   è¡¨æ ¼ä¸­æ ‡è®°ä¸ºâ€œâš ï¸æ˜¯â€çš„å±äºå‘¨æœŸæ€§è¡Œä¸šï¼ˆå¦‚èƒ½æºã€åŸææ–™ã€é‡‘èï¼‰ã€‚
                *   **ç‰¹ç‚¹**ï¼šåœ¨ç»æµç¹è£æ—¶ä¸šç»©æå¥½ï¼ˆä½PEã€é«˜ROEï¼‰ï¼Œç»æµè¡°é€€æ—¶ä¸šç»©æå·®ã€‚
                *   **æ³¨æ„**ï¼šå¯¹äºå‘¨æœŸè‚¡ï¼Œä½å¸‚ç›ˆç‡å¾€å¾€æ˜¯**å–å‡º**ä¿¡å·ï¼ˆè¡Œä¸šè§é¡¶ï¼‰ï¼Œé«˜å¸‚ç›ˆç‡å¾€å¾€æ˜¯**ä¹°å…¥**ä¿¡å·ï¼ˆè¡Œä¸šè§åº•ï¼‰ã€‚è¯·è°¨æ…æŠ•èµ„ï¼
                """)
    else:
        st.caption("å°šæœªè·å–æ•°æ®")
    
    if start_btn:
        # æ¸…é™¤ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°è·å–
        analyze_stocks.clear()
        
        with st.spinner('æ­£åœ¨å¼ºåˆ¶åˆ·æ–°æ•°æ®å¹¶åˆ†æï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰...'):
            tickers = get_sp500_tickers()
            if tickers:
                # æˆ‘ä»¬å¯ä»¥å…ˆåªå–å‰50ä¸ªåšæ¼”ç¤ºï¼Œå› ä¸º500ä¸ªå¤ªæ…¢äº†
                # æˆ–è€…å…¨é‡è·‘ï¼Œå› ä¸ºæœ‰ç¼“å­˜
                # ä¸ºäº†ä¿è¯â€œå¸‚å€¼å‰500åâ€ï¼ŒS&P 500å°±æ˜¯æœ€å¥½çš„ä»£è¡¨
                df = analyze_stocks(tickers) 
                st.session_state.data = df
                st.session_state.last_updated = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                save_cache(df) # ä¿å­˜ç¼“å­˜
                st.rerun() # é‡æ–°åŠ è½½ä»¥æ˜¾ç¤ºç»“æœå’Œæ›´æ–°æ—¶é—´
            else:
                st.error("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")

    if st.session_state.data is not None:
        df = st.session_state.data
        
        if df.empty:
            st.warning("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ‰€æœ‰æ¡ä»¶çš„è‚¡ç¥¨ã€‚")
        else:
            # æŒ‰ç…§å½“å‰ä»·æœ€æ¥è¿‘52å‘¨æœ€ä½ä»·æ’åº
            # è®¡ç®—é€»è¾‘ï¼š(å½“å‰ä»·æ ¼ - 52å‘¨æœ€ä½) / 52å‘¨æœ€ä½ï¼Œå€¼è¶Šå°è¶Šé å‰
            try:
                # ç¡®ä¿åˆ—æ˜¯æ•°å€¼ç±»å‹
                df['å½“å‰ä»·æ ¼'] = pd.to_numeric(df['å½“å‰ä»·æ ¼'], errors='coerce')
                df['52å‘¨æœ€ä½'] = pd.to_numeric(df['52å‘¨æœ€ä½'], errors='coerce')
                
                # è®¡ç®—åç¦»åº¦
                df['low_diff'] = (df['å½“å‰ä»·æ ¼'] - df['52å‘¨æœ€ä½']) / df['52å‘¨æœ€ä½']
                
                # æ’åº
                df = df.sort_values(by='low_diff', ascending=True)
            except Exception as e:
                st.error(f"æ’åºè®¡ç®—å‡ºé”™: {e}")

            # æ˜¾ç¤ºè¡¨æ ¼
            # æç¤ºç”¨æˆ·æ“ä½œ
            st.caption("ğŸ’¡ å•å‡»è¡¨æ ¼ä¸­çš„è¡ŒæŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ï¼ˆå·²æŒ‰æ¥è¿‘52å‘¨æœ€ä½ä»·æ’åºï¼‰")
            
            # ç»™æ•°å€¼åˆ—åŠ ä¸Šé¢œè‰²æ ·å¼
            # å®šä¹‰é¢œè‰²æ˜ å°„
            # è“è‰²: ä»·æ ¼, å¸‚å€¼ (åŸºæœ¬é¢è§„æ¨¡)
            # ç´«è‰²: PE (ä¼°å€¼)
            # ç»¿è‰²: ROE, æ¯›åˆ©ç‡ (ç›ˆåˆ©èƒ½åŠ›)
            # çº¢è‰²: è´Ÿå€ºç‡ (é£é™©)
            
            styled_df = df.style.applymap(lambda x: 'color: #2962FF; font-weight: 500;', subset=['å½“å‰ä»·æ ¼', '52å‘¨æœ€é«˜', '52å‘¨æœ€ä½', 'å¸‚å€¼(äº¿)', 'è‡ªç”±ç°é‡‘æµ(äº¿)']) \
                                .applymap(lambda x: 'color: #6200EA; font-weight: 500;', subset=['å¸‚ç›ˆç‡(PE)', 'PEG']) \
                                .applymap(lambda x: 'color: #00C853; font-weight: 500;', subset=['ROE(%)', 'æ¯›åˆ©ç‡(%)', 'å‡€åˆ©ç‡(%)']) \
                                .applymap(lambda x: 'color: #D50000; font-weight: 500;', subset=['å€ºåŠ¡æƒç›Šæ¯”(%)'])
            
            event = st.dataframe(
                styled_df,
                column_config={
                    "ä»£ç ": st.column_config.TextColumn("ä»£ç ", width="small"),
                    "ä¸­æ–‡åç§°": st.column_config.TextColumn("å…¬å¸åç§°", width="medium"),
                    "ä¸­æ–‡è¡Œä¸š": st.column_config.TextColumn("è¡Œä¸š", width="medium"),
                    "ä¼°å€¼çŠ¶æ€": st.column_config.TextColumn("ä¼°å€¼çŠ¶æ€", width="small", help="åŸºäºPEGå’Œè¥æ”¶å¢é•¿åˆ¤æ–­ï¼š\nğŸ’° ä½ä¼°ï¼šPEG < 1\nâš–ï¸ åˆç†ï¼š1 < PEG < 2\nğŸ”ï¸ é«˜ä¼°ï¼šPEG > 2\nğŸ“‰ è¡°é€€ï¼šè¥æ”¶è´Ÿå¢é•¿"),
                    "å½“å‰ä»·æ ¼": st.column_config.NumberColumn("ä»·æ ¼($)", format="$%.2f", width="small"),
                    "52å‘¨èŒƒå›´": st.column_config.TextColumn("52å‘¨èŒƒå›´ (ä½ - é«˜)", width="medium"),
                    "å¸‚ç›ˆç‡(PE)": st.column_config.NumberColumn("PE", format="%.2f", width="small"),
                    "PEG": st.column_config.NumberColumn("PEG", format="%.2f", width="small", help="å¸‚ç›ˆç‡ç›¸å¯¹ç›ˆåˆ©å¢é•¿æ¯”ç‡ï¼Œ<1é€šå¸¸ä¸ºä½ä¼°"),
                    "ROE(%)": st.column_config.NumberColumn("ROE", format="%.2f%%", width="small"),
                    "å€ºåŠ¡æƒç›Šæ¯”(%)": st.column_config.NumberColumn("è´Ÿå€ºç‡", format="%.2f%%", width="small"),
                    "æ¯›åˆ©ç‡(%)": st.column_config.NumberColumn("æ¯›åˆ©", format="%.2f%%", width="small"),
                    "å‡€åˆ©ç‡(%)": st.column_config.NumberColumn("å‡€åˆ©ç‡", format="%.2f%%", width="small", help="å‡€åˆ©æ¶¦å è¥æ”¶çš„æ¯”ä¾‹"),
                    "è‡ªç”±ç°é‡‘æµ(äº¿)": st.column_config.NumberColumn("FCF(äº¿)", format="$%.2f", width="small", help="è‡ªç”±ç°é‡‘æµï¼šå·´è²ç‰¹æœ€çœ‹é‡çš„çœŸé‡‘ç™½é“¶"),
                    "å¸‚å€¼(äº¿)": st.column_config.NumberColumn("å¸‚å€¼($äº¿)", format="$%.2f", width="small"),
                    "å‘¨æœŸè‚¡": st.column_config.TextColumn("å‘¨æœŸæ€§?", width="small", help="å‘¨æœŸæ€§è¡Œä¸šé€šå¸¸éšç»æµå‘¨æœŸæ³¢åŠ¨è¾ƒå¤§"),
                },
                column_order=[
                    "ä»£ç ", "ä¸­æ–‡åç§°", "ä¸­æ–‡è¡Œä¸š", "ä¼°å€¼çŠ¶æ€", "å‘¨æœŸè‚¡", 
                    "å½“å‰ä»·æ ¼", "52å‘¨èŒƒå›´", "å¸‚ç›ˆç‡(PE)", "PEG", "ROE(%)", 
                    "å€ºåŠ¡æƒç›Šæ¯”(%)", "æ¯›åˆ©ç‡(%)", "å‡€åˆ©ç‡(%)", "è‡ªç”±ç°é‡‘æµ(äº¿)", "å¸‚å€¼(äº¿)"
                ],
                hide_index=True,
                use_container_width=True,
                height=700,
                on_select="rerun",
                selection_mode="single-row"
            )
            
            # è‚¡ç¥¨è¯¦æƒ…æŸ¥çœ‹
            if len(event.selection.rows) > 0:
                selected_index = event.selection.rows[0]
                # æ³¨æ„ï¼šæ’åºåç´¢å¼•å˜äº†ï¼Œéœ€è¦ç”¨ iloc è·å–æ­£ç¡®çš„æ•°æ®
                selected_ticker = df.iloc[selected_index]['ä»£ç ']
                show_stock_details_dialog(selected_ticker)

@st.dialog("è‚¡ç¥¨è¯¦æƒ…", width="large")
def show_stock_details_dialog(ticker):
    # è‡ªå®šä¹‰ CSS æ¥è°ƒæ•´å¼¹çª—å®½åº¦
    # width="large" é€šå¸¸å¾ˆå®½ï¼Œè¿™é‡Œé€šè¿‡ max-width é™åˆ¶åœ¨ 900px å·¦å³ (æ¯”é»˜è®¤ large çª„ä¸€äº›ï¼Œæ¯” small å®½å¾ˆå¤š)
    st.markdown("""
        <style>
        div[role="dialog"][aria-modal="true"] {
            width: 80vw !important;
            max-width: 900px !important;
        }
        </style>
    """, unsafe_allow_html=True)
    show_stock_details(ticker)


# å·´è²ç‰¹æŒä»“æ•°æ® (é™æ€å¤‡ä»½ + æˆæœ¬æ•°æ®)
# æ•°æ®æ¥æº: 13F Filing via Dataroma/CNBC (æˆªè‡³ 2025å¹´ Q3)
BUFFETT_HOLDINGS_STATIC = {
    "AAPL": {"shares": 238212764, "cost": "çº¦ $35 (2016-2018å»ºä»“)"},
    "AXP": {"shares": 151610700, "cost": "çº¦ $8.49 (é•¿æœŸæŒæœ‰)"},
    "BAC": {"shares": 568070012, "cost": "çº¦ $14 (å«2017è¡Œæƒ)"},
    "KO": {"shares": 400000000, "cost": "çº¦ $3.25 (1988å¹´å»ºä»“)"},
    "CVX": {"shares": 122064792, "cost": "çº¦ $128 (2020å¹´èµ·å»ºä»“)"},
    "OXY": {"shares": 264941431, "cost": "çº¦ $52 (2019å¹´èµ·å»ºä»“)"},
    "MCO": {"shares": 24669778, "cost": "çº¦ $10 (2000å¹´åˆ†æ‹†)"},
    "CB": {"shares": 31332895, "cost": "çº¦ $230 - $291 (2023-2025å¢æŒ)"},
    "KHC": {"shares": 325634818, "cost": "çº¦ $30 (è´¦é¢ä»·å€¼)"},
    "GOOGL": {"shares": 17846142, "cost": "çº¦ $174 - $257 (2025 Q3å»ºä»“)"},
    "DVA": {"shares": 32160579, "cost": "çº¦ $45 (2011-2014å»ºä»“)"},
    "KR": {"shares": 50000000, "cost": "çº¦ $42 (2019-2021å»ºä»“)"},
    "SIRI": {"shares": 124807117, "cost": "çº¦ $25 (Libertyåˆå¹¶é‡ç»„)"},
    "V": {"shares": 8297460, "cost": "çº¦ $22 (2011å¹´å»ºä»“)"},
    "VRSN": {"shares": 8989880, "cost": "çº¦ $85 (2012-2013å»ºä»“)"},
    "MA": {"shares": 3986648, "cost": "çº¦ $25 (2011å¹´å»ºä»“)"},
    "AMZN": {"shares": 10000000, "cost": "çº¦ $90 (2019å¹´å»ºä»“)"},
    "STZ": {"shares": 13400000, "cost": "æœªå…¬å¼€ (å¯èƒ½ä¸ºå†å²é—ç•™)"},
    "UNH": {"shares": 5039564, "cost": "æœªå…¬å¼€"},
    "COF": {"shares": 7150000, "cost": "çº¦ $150 (2023-2024å»ºä»“)"},
    "AON": {"shares": 4100000, "cost": "çº¦ $300 (2021-2024å»ºä»“)"},
    "DPZ": {"shares": 2981945, "cost": "çº¦ $402 - $504 (2024-2025å»ºä»“)"},
    "ALLY": {"shares": 29000000, "cost": "çº¦ $35 (2022å¹´å»ºä»“)"},
    "LLYVK": {"shares": 10917661, "cost": "æœªå…¬å¼€"},
    "POOL": {"shares": 3458885, "cost": "çº¦ $310 - $350 (2024-2025å»ºä»“)"},
    "LEN": {"shares": 7050950, "cost": "çº¦ $115 (2023å¹´å»ºä»“)"},
    "NUE": {"shares": 6407749, "cost": "çº¦ $150 (2023-2024å»ºä»“)"},
    "LPX": {"shares": 5664793, "cost": "çº¦ $60 (2022-2023å»ºä»“)"},
    "LLYVA": {"shares": 4986588, "cost": "æœªå…¬å¼€"},
    "FWONK": {"shares": 3018555, "cost": "æœªå…¬å¼€"},
    "HEI-A": {"shares": 1294612, "cost": "çº¦ $160 - $200 (2024å»ºä»“)"},
    "CHTR": {"shares": 1060882, "cost": "çº¦ $160 (2014å¹´å»ºä»“)"},
    "LAMR": {"shares": 1202110, "cost": "çº¦ $100 - $123 (2025å»ºä»“)"},
    "ALLE": {"shares": 780133, "cost": "æœªå…¬å¼€"},
    "NVR": {"shares": 11112, "cost": "çº¦ $7000 (2023å¹´å»ºä»“)"},
    "DEO": {"shares": 227750, "cost": "çº¦ $160 (2023å¹´å»ºä»“)"},
    "JEF": {"shares": 433558, "cost": "çº¦ $30 (2022å¹´å»ºä»“)"},
    "LEN-B": {"shares": 180980, "cost": "çº¦ $100"},
    "LILA": {"shares": 2630792, "cost": "æœªå…¬å¼€"},
    "BATRK": {"shares": 223645, "cost": "æœªå…¬å¼€"},
    "LILAK": {"shares": 1284020, "cost": "æœªå…¬å¼€"}
}

def get_all_buffett_holdings():
    # 1. è·å–é™æ€æ•°æ®ä½œä¸ºåŸºç¡€
    holdings = BUFFETT_HOLDINGS_STATIC.copy()
    
    # 2. è·å–åŠ¨æ€æ•°æ®å¹¶æ›´æ–°
    dynamic_holdings = get_buffett_holdings_dynamic()
    if dynamic_holdings:
        for ticker, data in dynamic_holdings.items():
            if ticker in holdings:
                # æ›´æ–°æŒä»“æ•°é‡ï¼Œä¿ç•™é™æ€æ•°æ®ä¸­çš„æˆæœ¬ä¿¡æ¯
                holdings[ticker]['shares'] = data['shares']
                # å¦‚æœé™æ€æ•°æ®æ²¡æœ‰æˆæœ¬ä¿¡æ¯ï¼Œæˆ–è€…åŠ¨æ€æ•°æ®æœ‰æ›´ä¸°å¯Œçš„ä¿¡æ¯(è™½ç„¶ç›®å‰scraperæ²¡æœ‰)ï¼Œå¯ä»¥åœ¨è¿™é‡Œå¤„ç†
            else:
                # æ–°å¢æŒä»“
                holdings[ticker] = data
    
    return holdings

@st.cache_data(ttl=604800, show_spinner=False) # ç¼“å­˜7å¤©
def get_stock_details_cached(ticker):
    # å¢åŠ éšæœºå»¶è¿Ÿ
    time.sleep(random.uniform(0.1, 0.5))
    
    max_retries = 3
    for i in range(max_retries):
        try:
            stock = yf.Ticker(ticker)
            info = stock.info
            # ç®€å•çš„æœ‰æ•ˆæ€§æ£€æŸ¥
            if info and 'currentPrice' in info:
                return info
        except Exception as e:
            if i < max_retries - 1:
                time.sleep(random.uniform(1, 3) * (i + 1))
            else:
                print(f"Failed to fetch details for {ticker}: {e}")
                
    # å°è¯•å¤‡ç”¨æ¥å£ (ç®€å•çš„é¡µé¢è¯·æ±‚æµ‹è¯•)
    try:
        url = f"https://finance.yahoo.com/quote/{ticker}"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        resp = requests.get(url, headers=headers, timeout=5)
        if resp.status_code == 200:
            return {'__backup_mode__': True}
    except Exception:
        pass
        
    return None

def get_industry_averages(industry):
    if 'data' in st.session_state and st.session_state.data is not None:
        df = st.session_state.data
        # ç­›é€‰åŒè¡Œä¸š
        industry_df = df[df['è¡Œä¸š'] == industry]
        count = len(industry_df)
        if not industry_df.empty:
            avg_pe = industry_df['å¸‚ç›ˆç‡(PE)'].mean()
            avg_roe = industry_df['ROE(%)'].mean()
            avg_de = industry_df['å€ºåŠ¡æƒç›Šæ¯”(%)'].mean()
            avg_margin = industry_df['æ¯›åˆ©ç‡(%)'].mean()
            return {
                'count': count,
                'avg_pe': f"{avg_pe:.2f}",
                'avg_roe': f"{avg_roe:.2f}%",
                'avg_de': f"{avg_de:.2f}%",
                'avg_margin': f"{avg_margin:.2f}%"
            }
    return {'count': 0}

def format_value(val, fmt="{:.2f}"):
    if val is None or val == 'N/A' or val == '':
        return "N/A"
    try:
        return fmt.format(float(val))
    except:
        return str(val)

def show_stock_details(ticker):
    try:
        # 1. å°è¯•è·å–è¯¦ç»†ä¿¡æ¯ (å¸¦ç¼“å­˜)
        info = get_stock_details_cached(ticker)
        
        is_backup_mode = False
        
        # 2. å¦‚æœè·å–å¤±è´¥æˆ–å¤„äºå¤‡ç”¨æ¨¡å¼ï¼Œæ„é€ é™çº§æ•°æ®
        if not info or info.get('__backup_mode__'):
            is_backup_mode = True
            # ä» session_state ä¸­æ¢å¤æ•°æ®
            if 'data' in st.session_state and st.session_state.data is not None:
                df = st.session_state.data
                row = df[df['ä»£ç '] == ticker]
                if not row.empty:
                    row = row.iloc[0]
                    # æ„é€ åŸºç¡€ info å¯¹è±¡
                    info = {
                        'shortName': row.get('åç§°', ticker),
                        'currentPrice': row.get('å½“å‰ä»·æ ¼'),
                        'fiftyTwoWeekHigh': row.get('52å‘¨æœ€é«˜'),
                        'fiftyTwoWeekLow': row.get('52å‘¨æœ€ä½'),
                        'marketCap': row.get('marketCap', row.get('å¸‚å€¼(äº¿)', 0) * 100000000),
                        'trailingPE': row.get('trailingPE', row.get('å¸‚ç›ˆç‡(PE)')),
                        'forwardPE': row.get('forwardPE'),
                        'pegRatio': row.get('pegRatio'),
                        'priceToBook': row.get('priceToBook'),
                        'enterpriseValue': row.get('enterpriseValue'),
                        'returnOnEquity': row.get('returnOnEquity', row.get('ROE(%)', 0) / 100),
                        'debtToEquity': row.get('debtToEquity', row.get('å€ºåŠ¡æƒç›Šæ¯”(%)')),
                        'grossMargins': row.get('grossMargins', row.get('æ¯›åˆ©ç‡(%)', 0) / 100),
                        'industry': row.get('è¡Œä¸š'),
                        'longBusinessSummary': row.get('longBusinessSummary', 'âš ï¸ ç½‘ç»œç¹å¿™æˆ–APIå—é™ï¼Œå½“å‰æ˜¾ç¤ºä¸ºç¼“å­˜çš„åŸºç¡€æ•°æ®ã€‚è¯¦ç»†ç®€ä»‹æš‚æ—¶æ— æ³•è·å–ã€‚'),
                        'dividendYield': row.get('dividendYield')
                    }
                else:
                    st.error("æ— æ³•è·å–è¯¦æƒ…ï¼Œä¸”æ‰¾ä¸åˆ°ç¼“å­˜çš„åŸºç¡€æ•°æ®ã€‚")
                    return
            else:
                st.error("æ— æ³•è·å–è¯¦æƒ… (API Rate Limit)ã€‚")
                return

        st.markdown(f"### {info.get('shortName')} ({ticker})")
        if is_backup_mode:
             st.warning("å½“å‰å¤„äºå¤‡ç”¨æ•°æ®æ¨¡å¼ (APIé™æµä¿æŠ¤)ï¼Œå·²åŠ è½½æœ¬åœ°ç¼“å­˜çš„å®Œæ•´æ•°æ®ã€‚")
        
        # å®šä¹‰è‡ªå®šä¹‰æŒ‡æ ‡ç»„ä»¶ (å¸¦é¢œè‰²)
        def custom_metric(label, value, color="#2962FF"):
            st.markdown(f"<div style='font-size: 14px; color: rgba(49, 51, 63, 0.6); margin-bottom: -10px;'>{label}</div>", unsafe_allow_html=True)
            st.markdown(f"<div style='font-size: 24px; font-weight: 600; color: {color}; overflow-wrap: break-word; line-height: 1.2; margin-bottom: 1rem;'>{value}</div>", unsafe_allow_html=True)

        col1, col2, col3 = st.columns(3)
        with col1:
            current_price = info.get('currentPrice')
            custom_metric("å½“å‰ä»·æ ¼", f"${current_price}" if current_price else "æœªè·å–åˆ°")
        with col2:
            fifty_two_week_high = info.get('fiftyTwoWeekHigh')
            custom_metric("52å‘¨æœ€é«˜", f"${fifty_two_week_high}" if fifty_two_week_high else "æœªè·å–åˆ°")
        with col3:
            fifty_two_week_low = info.get('fiftyTwoWeekLow')
            custom_metric("52å‘¨æœ€ä½", f"${fifty_two_week_low}" if fifty_two_week_low else "æœªè·å–åˆ°")
            
        st.markdown("#### å…¬å¸ç®€ä»‹")
        # å°è¯•ç¿»è¯‘ç®€ä»‹æˆ–è€…ç›´æ¥æ˜¾ç¤ºè‹±æ–‡
        summary = info.get('longBusinessSummary', 'æš‚æ— ç®€ä»‹')
        if summary and summary != 'æš‚æ— ç®€ä»‹':
            # å¦‚æœç®€ä»‹å¤ªé•¿ï¼ŒGoogle Translate APIå¯èƒ½ä¼šæŠ¥é”™ï¼Œå¯ä»¥è€ƒè™‘æˆªæ–­æˆ–è€…åˆ†æ®µï¼Œè¿™é‡Œå…ˆç›´æ¥å°è¯•
            # ä¸ºäº†æ›´å¥½çš„ä½“éªŒï¼Œå¯ä»¥åœ¨è¿™é‡Œæ˜¾ç¤ºâ€œæ­£åœ¨ç¿»è¯‘...â€
            summary = translate_text(summary)
        st.write(summary)
        
        # å·´è²ç‰¹æŒä»“æƒ…å†µ (æ–°å¢)
        st.markdown("#### ğŸ¦ å·´è²ç‰¹æŒä»“æƒ…å†µ")
        
        # æ ‡å‡†åŒ– ticker (å°† . æ›¿æ¢ä¸º - ä»¥åŒ¹é…å­—å…¸é”®)
        lookup_ticker = ticker.replace('.', '-')
        
        # è·å–æœ€æ–°çš„æŒä»“æ•°æ® (åŠ¨æ€åˆå¹¶)
        all_holdings = get_all_buffett_holdings()
        
        if lookup_ticker in all_holdings:
            holding = all_holdings[lookup_ticker]
            shares = holding['shares']
            cost = holding['cost']
            
            # è®¡ç®—æŒä»“å¸‚å€¼ (å¦‚æœèƒ½è·å–åˆ°å½“å‰ä»·æ ¼)
            current_price = info.get('currentPrice')
            market_value_str = "æœªè·å–åˆ°"
            if current_price and shares:
                 market_value = current_price * shares
                 market_value_str = f"${market_value:,.2f}"
            
            st.success(f"âœ… å·´è²ç‰¹ (Berkshire Hathaway) æŒæœ‰æ­¤è‚¡")
            
            b_col1, b_col2, b_col3 = st.columns(3)
            with b_col1:
                custom_metric("æŒä»“æ•°é‡", f"{shares:,} è‚¡", color="#2962FF")
            with b_col2:
                custom_metric("å½“å‰æŒä»“å¸‚å€¼", market_value_str, color="#2962FF")
            with b_col3:
                custom_metric("ä¼°è®¡æˆæœ¬", cost, color="#FF6D00") # æ©™è‰²æ˜¾ç¤ºæˆæœ¬
                
            st.caption(f"æ•°æ®æ¥æº: Berkshire Hathaway 13F Filing (åŠ¨æ€æ›´æ–°). æˆæœ¬æ•°æ®ä»…ä¸ºä¼°è®¡æˆ–æœªå…¬å¼€ã€‚")
        else:
            st.info("â„¹ï¸ å·´è²ç‰¹ (Berkshire Hathaway) å½“å‰æœªæŒæœ‰æ­¤è‚¡ (åŸºäºæœ€æ–° 13F æ•°æ®)")

        st.markdown("#### æ ¸å¿ƒè´¢åŠ¡æ•°æ®")
        
        # æ ¼å¼åŒ–è‚¡æ¯ç‡
        div_yield = info.get('dividendYield')
        if div_yield is not None:
            # yfinance è¿”å›çš„ dividendYield é€šå¸¸å·²ç»æ˜¯ç™¾åˆ†æ¯”æ•°å€¼ (ä¾‹å¦‚ 0.38 ä»£è¡¨ 0.38%, 7.34 ä»£è¡¨ 7.34%)
            # ä¸éœ€è¦ä¹˜ä»¥ 100
            div_yield_str = f"{div_yield:.2f}%"
        else:
            div_yield_str = "N/A"

        # è®¡ç®—è¡Œä¸šå‡å€¼
        industry = info.get('industry')
        avgs = get_industry_averages(industry) if industry else {'count': 0}
        
        count = avgs.get('count', 0)
        
        if count > 1:
            avg_col_name = f"åŒæ¦œè¡Œä¸šå‡å€¼ (å…±{count}å®¶)"
            avg_pe = avgs.get('avg_pe', '-')
            avg_roe = avgs.get('avg_roe', '-')
            avg_de = avgs.get('avg_de', '-')
            avg_margin = avgs.get('avg_margin', '-')
        else:
            avg_col_name = "åŒæ¦œè¡Œä¸šå‡å€¼"
            avg_pe = "ä»…æ­¤ä¸€å®¶å…¥é€‰"
            avg_roe = "ä»…æ­¤ä¸€å®¶å…¥é€‰"
            avg_de = "ä»…æ­¤ä¸€å®¶å…¥é€‰"
            avg_margin = "ä»…æ­¤ä¸€å®¶å…¥é€‰"
        
        # å‡†å¤‡æ•°æ®
        roe = info.get('returnOnEquity')
        roe_str = f"{roe * 100:.2f}%" if roe is not None else "N/A"
        
        de_ratio = info.get('debtToEquity')
        de_str = f"{de_ratio:.2f}%" if de_ratio is not None else "N/A"
        
        gross_margins = info.get('grossMargins')
        gm_str = f"{gross_margins * 100:.2f}%" if gross_margins is not None else "N/A"

        # å®‰å…¨è·å–å¹¶æ ¼å¼åŒ–æ•°å€¼ï¼Œé˜²æ­¢ NoneType é”™è¯¯
        market_cap_val = info.get('marketCap')
        market_cap_str = f"${market_cap_val:,}" if market_cap_val is not None else "N/A"

        ev_val = info.get('enterpriseValue')
        ev_str = f"${ev_val:,}" if ev_val is not None else "N/A"

        fin_data = {
            "æŒ‡æ ‡": [
                "æ€»å¸‚å€¼", "ä¼ä¸šä»·å€¼", "é™æ€å¸‚ç›ˆç‡ (TTM)", "é¢„æµ‹å¸‚ç›ˆç‡ (Forward)", "PEG æ¯”ç‡", 
                "å¸‚å‡€ç‡ (P/B)", "è‚¡æ¯ç‡", "ROE (å‡€èµ„äº§æ”¶ç›Šç‡)", "è´Ÿå€ºæƒç›Šæ¯” (è´Ÿå€ºç‡)", "æ¯›åˆ©ç‡"
            ],
            "æ•°å€¼": [
                market_cap_str,
                ev_str,
                format_value(info.get('trailingPE')),
                format_value(info.get('forwardPE')),
                format_value(info.get('pegRatio')),
                format_value(info.get('priceToBook')),
                div_yield_str,
                roe_str,
                de_str,
                gm_str
            ],
            avg_col_name: [
                "", "", avg_pe, "", "", 
                "", "", avg_roe, avg_de, avg_margin
            ]
        }
        
        fin_df = pd.DataFrame(fin_data)
        
        # å®šä¹‰æ¯ä¸€è¡Œçš„é¢œè‰²æ ·å¼
        # 0: æ€»å¸‚å€¼ (è“)
        # 1: ä¼ä¸šä»·å€¼ (è“)
        # 2-5: ä¼°å€¼æŒ‡æ ‡ PE, PEG, PB (ç´«)
        # 6: è‚¡æ¯ç‡ (ç»¿)
        # 7: ROE (ç»¿)
        # 8: è´Ÿå€ºç‡ (çº¢)
        # 9: æ¯›åˆ©ç‡ (ç»¿)
        
        def highlight_metrics(row):
            styles = [''] * len(row) # åˆå§‹åŒ–æ ·å¼åˆ—è¡¨
            idx = row.name # è·å–è¡Œç´¢å¼•
            
            color = 'black'
            if idx in [0, 1]:
                color = '#2962FF' # è“
            elif idx in [2, 3, 4, 5]:
                color = '#6200EA' # ç´«
            elif idx in [6, 7, 9]:
                color = '#00C853' # ç»¿
            elif idx == 8:
                color = '#D50000' # çº¢
            
            # åº”ç”¨é¢œè‰²åˆ°æ•°å€¼åˆ— (ç¬¬1åˆ—å’Œç¬¬2åˆ—ï¼Œç´¢å¼•ä¸º1å’Œ2)
            # pandas series index: 0=æŒ‡æ ‡, 1=æ•°å€¼, 2=avg_col_name
            styles[1] = f'color: {color}; font-weight: 500;'
            styles[2] = f'color: {color}; font-weight: 500;'
            
            return styles

        # ä½¿ç”¨ apply å¯¹æ¯ä¸€è¡Œåº”ç”¨æ ·å¼
        styled_fin_df = fin_df.style.apply(highlight_metrics, axis=1)
        st.table(styled_fin_df)
        
    except Exception as e:
        st.error(f"æ— æ³•è·å–è¯¦æƒ…: {e}")

if __name__ == "__main__":
    main()
